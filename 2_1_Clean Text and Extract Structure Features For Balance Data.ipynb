{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065cc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import mwparserfromhell\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caaf824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(df):\n",
    "    \"\"\"\n",
    "    Remove NaN value from rate, importance and text\n",
    "    \n",
    "    df: dataframe of articles\n",
    "    \"\"\"\n",
    "    print(\"NaN rate: \", len(np.where(df['rate'].isnull())[0]))\n",
    "    print(\"NaN importance: \", len(np.where(df['importance'].isnull())[0]))\n",
    "    print(\"NaN text: \", len(np.where(df['text'].isnull())[0]))\n",
    "    \n",
    "    df = df[df['rate'].notna()]\n",
    "    df = df[df['importance'].notna()]\n",
    "    df = df[df['text'].notna()]\n",
    "    print(f\"Number of rows after drop NaN: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca01d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wikipedia_text(text):\n",
    "    \"\"\"\n",
    "    Clean article text\n",
    "    \n",
    "    text: article text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove anything after \"== See also ==\"\n",
    "    see_also_index = text.find(\"== See also ==\")\n",
    "    if see_also_index != -1:\n",
    "        text = text[:see_also_index]\n",
    "    \n",
    "    wikicode = mwparserfromhell.parse(text) # convert to wiki object\n",
    "    \n",
    "    # remove templates\n",
    "    for template in wikicode.filter_templates(recursive=False):\n",
    "        wikicode.remove(template)\n",
    "    \n",
    "    # convert to plain text\n",
    "    plain_text = wikicode.strip_code()\n",
    "    \n",
    "    plain_text = re.sub(r'thumb\\|.*?\\.', '', plain_text)\n",
    "    plain_text = re.sub(r\"\\\\('s)\", r\"\\1\", str(plain_text))\n",
    "    \n",
    "    # normalize whitespace\n",
    "    plain_text = re.sub(r'\\s+', ' ', plain_text).strip()\n",
    "    \n",
    "    return plain_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f5c660",
   "metadata": {},
   "source": [
    "# Extract Feature Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede1dc5",
   "metadata": {},
   "source": [
    "## Get number of reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea743c32",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def number_of_reference(text):\n",
    "    \"\"\"\n",
    "    Get number of reference in each articles\n",
    "    \n",
    "    text: article text\n",
    "    \"\"\"\n",
    "\n",
    "    # find reference in this format {{Sfn: }} or {{Sfnm: }}\n",
    "    substrings = list(set(re.findall(r\"\\{\\{Sfn(?:\\||m\\|)[^}]*\\}\\}\", text)))\n",
    "    if len(substrings) > 0:\n",
    "        return len(substrings)\n",
    "    \n",
    "    # find reference by using mwparserfromhell\n",
    "    wiki = mwparserfromhell.parse(text) # convert to wiki object\n",
    "    references = wiki.filter_tags(matches=lambda node: node.tag == \"ref\")\n",
    "    \n",
    "    ref_name = []\n",
    "    unique_ref = []\n",
    "    for ref in references:\n",
    "        if len([att for att in ref.attributes if 'name=\\\"' in att]): # if reference have name\n",
    "            attribute = [att for att in ref.attributes if 'name=\\\"' in att][0] # get the name of reference\n",
    "            \n",
    "            if attribute not in ref_name: # if reference name is new\n",
    "                unique_ref.append(ref)\n",
    "                ref_name.append(attribute)\n",
    "        else:\n",
    "            unique_ref.append(ref)\n",
    "            \n",
    "    return len(unique_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71541e39",
   "metadata": {},
   "source": [
    "## Get number of external and internal links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d468800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_links(wiki):\n",
    "    ex_links = wiki.filter_external_links()\n",
    "    wiki_links = wiki.filter_wikilinks()\n",
    "    \n",
    "    return len(ex_links), len(wiki_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4cf2a7",
   "metadata": {},
   "source": [
    "## Get number of tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9419dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_tables(wiki):\n",
    "    tables = wiki.filter_tags(matches=lambda tag: tag.tag == \"table\")\n",
    "    return len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aab887",
   "metadata": {},
   "source": [
    "## Get number of formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b4c2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_formula(wiki):\n",
    "    formulas = wiki.filter_tags(matches=lambda node: node.tag == \"math\")\n",
    "    return len(formulas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54375df6",
   "metadata": {},
   "source": [
    "## Get number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73ae42e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_image(wiki):\n",
    "    images = wiki.filter_wikilinks(matches=lambda link: link.title.startswith(\"File:\"))\n",
    "    return len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c8985",
   "metadata": {},
   "source": [
    "## Get number of paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f32e00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_paragraph(text):\n",
    "    paragraphs = len(re.findall(r'\\n\\n', text)) + 1\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d80bcc",
   "metadata": {},
   "source": [
    "## Get number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e95e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_sentence(text):\n",
    "    sentences = len(re.split(r'[.!?]', text))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8972bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    \"\"\"\n",
    "    Clean Text and add Structure Features\n",
    "    \n",
    "    df: dataframe of articles\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Start Cleaning Text ....\")\n",
    "    start_time = time.time()\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['text']        \n",
    "        df.loc[index, 'clean_text'] = clean_wikipedia_text(text)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Clean Text time: {elapsed_time/60:.2f} minutes\")\n",
    "    \n",
    "    # Remove NaN value from clean text\n",
    "    print(\"NaN clean text: \", len(np.where(df['clean_text'].isnull())[0]))\n",
    "    df = df[df['clean_text'].notna()]\n",
    "    print(\"Number of rows after drop NaN : \", df.shape[0])\n",
    "    \n",
    "    print(\"Start Getting Structure Features ....\")\n",
    "    start_time = time.time()\n",
    "    for index, row in df.iterrows():\n",
    "        wiki = mwparserfromhell.parse(row['text']) # convert to wiki object\n",
    "        text = row['text']\n",
    "        \n",
    "        df.loc[index, 'reference'] = number_of_reference(text)\n",
    "        \n",
    "        ex_links, wiki_links = number_of_links(wiki)\n",
    "        df.loc[index, 'external_link'] = ex_links\n",
    "        df.loc[index, 'internal_link'] = wiki_links\n",
    "        \n",
    "        df.loc[index, 'table'] = number_of_tables(wiki)\n",
    "        df.loc[index, 'formula'] = number_of_formula(wiki)\n",
    "        df.loc[index, 'images'] = number_of_image(wiki)\n",
    "\n",
    "        headings = wiki.filter_headings()\n",
    "\n",
    "        # Count number of sections, subsections, sub-subsections\n",
    "        sections = sum(1 for heading in headings if heading.level == 2)\n",
    "        df.loc[index, 'section'] = sections\n",
    "\n",
    "        subsections = sum(1 for heading in headings if heading.level == 3)\n",
    "        df.loc[index, 'subsection'] = subsections\n",
    "\n",
    "        subsubsections = sum(1 for heading in headings if heading.level == 4)\n",
    "        df.loc[index, 'subsubsection'] = subsubsections\n",
    "        \n",
    "        df.loc[index, 'paragraph'] = number_of_paragraph(text)\n",
    "        df.loc[index, 'sentence'] = number_of_sentence(text)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Get Structure Features time: {elapsed_time/60:.2f} minutes\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a9aeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file alreday exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('../Data/dataset_text_structure_(Balance).csv'):\n",
    "    df = pd.read_csv('../Data/initial_dataset_(Balance).csv', keep_default_na=False)\\\n",
    "    \n",
    "    start_time = time.time()\n",
    "    df = filter_date(df)\n",
    "    df = add_features(df)\n",
    "    df.to_csv('../Data/dataset_text_structure_(Balance).csv', index=False)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time/60:.2f} minutes\")\n",
    "    print(\"CSV file created\")\n",
    "else:\n",
    "    df = pd.read_csv(f'../Data/dataset_text_structure_(Balance).csv', keep_default_na=False)\n",
    "    print(\"CSV file alreday exists\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
